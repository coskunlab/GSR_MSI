{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f798a4-cbc9-47fb-86a0-ea1a92f86bd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_PROC_BIND\"] = os.environ.get(\"OMP_PROC_BIND\", \"true\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pix_transform_diff_models import PixTransform_diff_models\n",
    "from pix_transform_net_diff_models import PixTransformNetBase, PixTransformNetDeeper, PixTransformNetAttention, PixTransformNetMultiScale, PixTransformNetResidual\n",
    "from baselines.baselines import bicubic\n",
    "from utils.utils import downsample,align_images\n",
    "from utils.plots import plot_result\n",
    "import cv2\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "import json\n",
    "from skimage.color import label2rgb\n",
    "from PIL import Image\n",
    "from scipy.stats import zscore\n",
    "import tifffile\n",
    "from skimage import exposure\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0991666-17c7-4bc2-b8f8-897ad5051fe1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to adjust image contrast\n",
    "def enhance_contrast(image):\n",
    "    # Perform contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    image_rescale = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "    return image_rescale\n",
    "\n",
    "tissue = 'C_01'\n",
    "imc_dir = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\'\n",
    "for imc_img_dir in os.listdir(imc_dir)[:-1]:\n",
    "    if imc_img_dir == 'Thumbs.db':\n",
    "        continue\n",
    "    imc_img = tifffile.imread(imc_dir + imc_img_dir)\n",
    "    imc_img = enhance_contrast(imc_img)\n",
    "    plt.imshow(imc_img)\n",
    "    plt.title(imc_img_dir)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb190f9-5640-4ada-8948-f7251507987e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imc_dna = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\191Ir_DNA1.ome.tiff'\n",
    "imc_vimentin = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\194Pt_Vimentin.ome.tiff'\n",
    "imc_bcat = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\196Pt_Bcatenin.ome.tiff'\n",
    "imc_foxp3 = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\159Tb_FOXP3.ome.tiff'\n",
    "imc_ki67 = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\152Sm_Ki-67.ome.tiff'\n",
    "imc_keratin = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\198Pt_Keratin.ome.tiff'\n",
    "imc_cd45 = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\IMC_images+masks\\\\Tissue_{tissue}\\\\channels\\\\149Sm_CD45.ome.tiff'\n",
    "\n",
    "imc_dir_lst = [imc_dna, imc_vimentin, imc_bcat, imc_foxp3, imc_ki67, imc_keratin, imc_cd45]\n",
    "\n",
    "# Function to adjust image contrast\n",
    "def enhance_contrast(image):\n",
    "    # Perform contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    image_rescale = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "    return image_rescale\n",
    "\n",
    "imc_img_norm_lst = []\n",
    "for i in range(len(imc_dir_lst)):\n",
    "    imc_img = tifffile.imread(imc_dir_lst[i])\n",
    "    imc_img_enhanced = enhance_contrast(imc_img)\n",
    "    imc_img_norm = imc_img_enhanced / np.max(imc_img_enhanced)\n",
    "    imc_img_norm_lst.append(imc_img_norm)\n",
    "    plt.imshow(imc_img_norm)\n",
    "    plt.show()\n",
    "\n",
    "dna_norm = imc_img_norm_lst[0].copy()\n",
    "vimentin_norm = imc_img_norm_lst[1].copy()\n",
    "bcat_norm = imc_img_norm_lst[2].copy()\n",
    "foxp3_norm = imc_img_norm_lst[3].copy()\n",
    "ki67_norm = imc_img_norm_lst[4].copy()\n",
    "keratin_norm = imc_img_norm_lst[5].copy()\n",
    "cd45_norm = imc_img_norm_lst[6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb4b829-28a8-41c0-a1cf-3eba91a7e9a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "guide_img = dna_norm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbfb0c8-27fd-44be-9e4c-0226e20ffb8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msi_dir = f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\MALDI_singleTIFF\\\\Tissue_{tissue}\\\\'\n",
    "msi_img_list = []\n",
    "for msi_img_dir in os.listdir(msi_dir):\n",
    "    if msi_img_dir == 'Thumbs.db':\n",
    "        continue\n",
    "    msi_img = tifffile.imread(msi_dir + msi_img_dir)\n",
    "    msi_img = np.flip(msi_img)\n",
    "    msi_img = ((msi_img - msi_img.min()) / (msi_img.max() - msi_img.min()) * 255).astype(np.uint8)\n",
    "    msi_img_list.append(msi_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43090ca-8312-42ce-8a41-24d19b7f0466",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(msi_img_list))[:10]:\n",
    "    print(i)\n",
    "    plt.imshow(msi_img_list[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e56687-2c31-4a5d-b7d7-02dd326f9241",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metabolites_idx = range(len(msi_img_list))\n",
    "msi_img_list = [msi_img_list[i] for i in metabolites_idx]\n",
    "\n",
    "for i in range(len(msi_img_list))[:10]:\n",
    "    print(i)\n",
    "    plt.imshow(msi_img_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9052cdc1-b528-4a6f-b8f2-d9a3e8c6111b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clip_image(data,x_neg_offset,x_pos_offset,y_neg_offset,y_pos_offset):\n",
    "    return data[y_neg_offset:(data.shape[0]-y_pos_offset),x_neg_offset:(data.shape[1]-x_pos_offset)]\n",
    "\n",
    "if tissue == 'A_01':\n",
    "    guide_clip_params = (30, 0, 90, 0)\n",
    "    msi_clip_params = (0, 3, 0, 12)\n",
    "elif tissue == 'A_02':\n",
    "    guide_clip_params = (0, 60, 0, 295)\n",
    "    msi_clip_params = (9, 0, 53, 0)\n",
    "elif tissue == 'B_01':\n",
    "    guide_clip_params = (275, 0, 0, 150)\n",
    "    msi_clip_params = (0, 52, 25, 0)\n",
    "elif tissue == 'B_02':\n",
    "    guide_clip_params = (150, 0, 0, 135)\n",
    "    msi_clip_params = (0, 27, 21, 0)\n",
    "elif tissue == 'C_01':\n",
    "    guide_clip_params = (0, 70, 10, 20)\n",
    "    msi_clip_params = (1, 0, 0, 0)\n",
    "elif tissue == 'C_02':\n",
    "    guide_clip_params = (7, 8, 30, 0)\n",
    "    msi_clip_params = (0, 0, 0, 1)\n",
    "\n",
    "guide_img = clip_image(guide_img, *guide_clip_params)\n",
    "\n",
    "for i in range(len(msi_img_list)):\n",
    "    msi_img = clip_image(msi_img_list[i], *msi_clip_params)\n",
    "    msi_img_list[i] = msi_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa16385c-5194-454b-9e44-5d86b8f8c98c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metabolites_df = pd.read_excel(f'Y:\\\\coskun-lab\\\\Efe\\\\gsr_imc\\\\datasets\\\\integration_mass_cytometry_data\\\\Coregistration\\\\Coregistration_files\\\\MALDI_singleTIFF\\\\41592_2024_2392_MOESM4_ESM.xlsx')\n",
    "metabolites_df = metabolites_df[['m/z', 'Short name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b64f48-fb45-48b8-83cf-5c875a461cab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def calculate_entropy(image):\n",
    "    \"\"\"Calculate the Shannon entropy of a 2D image.\"\"\"\n",
    "    pixel_values = image.flatten()\n",
    "    \n",
    "    # Get the histogram of pixel values (probability distribution)\n",
    "    hist, bin_edges = np.histogram(pixel_values, bins=256, density=True)\n",
    "    \n",
    "    # Calculate the entropy using the histogram\n",
    "    return entropy(hist)\n",
    "\n",
    "def calculate_local_entropy(image, patch_size):\n",
    "    \"\"\"Calculate the entropy for patches within the image.\"\"\"\n",
    "    h, w = image.shape\n",
    "    patch_entropies = []\n",
    "    \n",
    "    # Divide the image into patches and calculate entropy for each patch\n",
    "    for i in range(0, h, patch_size):\n",
    "        for j in range(0, w, patch_size):\n",
    "            patch = image[i:i+patch_size, j:j+patch_size]\n",
    "            patch_entropy = calculate_entropy(patch)\n",
    "            patch_entropies.append(patch_entropy)\n",
    "    \n",
    "    # Combine the patch entropies (sum, mean, or max could be used)\n",
    "    return np.mean(patch_entropies)\n",
    "\n",
    "def rank_images_by_local_entropy(image_list, patch_size=32):\n",
    "    \"\"\"Rank a list of 2D numpy arrays based on their local entropy.\"\"\"\n",
    "    entropies = [calculate_local_entropy(img, patch_size) for img in image_list]\n",
    "    \n",
    "    # Rank the images based on the entropies (sorting by entropy in descending order)\n",
    "    sorted_indices = np.argsort(entropies)[::-1]  # Get indices sorted by entropy, descending\n",
    "    \n",
    "    # Get the ranked images by using the sorted indices\n",
    "    ranked_images = [image_list[i] for i in sorted_indices]\n",
    "    \n",
    "    return ranked_images, sorted_indices\n",
    "\n",
    "select_top = False\n",
    "\n",
    "if select_top == True:\n",
    "    # Example usage\n",
    "    patch_size = 16  # Adjust the patch size based on the image resolution\n",
    "    ranked_msi_img_list, sorted_indices = rank_images_by_local_entropy(msi_img_list, patch_size)\n",
    "    \n",
    "    print(\"Ranked image indices:\", sorted_indices)\n",
    "    \n",
    "    msi_img_list = ranked_msi_img_list[:40]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(guide_img)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(msi_img_list[0])\n",
    "    print(guide_img.shape)\n",
    "    print(msi_img_list[0].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee0a70f-036a-4f96-95dc-6fdf21dcea9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_id = 35\n",
    "base_dir = f'Y:\\\\coskun-lab\\\\Efe and Nishkala\\\\gsrmsi\\\\GUIDEDSR\\\\09_30_2024\\\\integration_mass_cytometry_data\\\\{unique_id}'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4f2d33-d045-42bf-a487-ce8b6280fe47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def crop_to_square(img):\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    if height == width:\n",
    "        return img\n",
    "    \n",
    "    if height > width:\n",
    "        # Crop the height\n",
    "        start = (height - width) // 2\n",
    "        end = start + width\n",
    "        cropped_img = img[start:end, :]\n",
    "    else:\n",
    "        # Crop the width\n",
    "        start = (width - height) // 2\n",
    "        end = start + height\n",
    "        cropped_img = img[:, start:end]\n",
    "    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd935eb-72ee-4c94-96af-1c70e9c38717",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guide_size = 1024\n",
    "source_size = 256\n",
    "\n",
    "guide_resized = cv2.resize(crop_to_square(guide_img), (guide_size, guide_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "msi_img_resized_list = []\n",
    "for i in range(len(msi_img_list)):\n",
    "    msi_resized = cv2.resize(crop_to_square(msi_img_list[i]), (source_size, source_size), interpolation=cv2.INTER_NEAREST)\n",
    "    msi_img_resized_list.append(msi_resized)\n",
    "\n",
    "for i in range(len(msi_img_list))[:10]: \n",
    "    plt.imshow(msi_img_resized_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958563c8-7557-443b-bf86-b0af9fe999b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(guide_resized,cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.resize(msi_img_resized_list[0], (guide_resized.shape[1], guide_resized.shape[0]), interpolation=cv2.INTER_NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623e6f-b2d9-423a-ac44-a0b0476bc256",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply Denoising\n",
    "msi_img_denoised_list = []\n",
    "for img in msi_img_resized_list:\n",
    "    msi_img_denoised = cv2.fastNlMeansDenoising(img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    msi_img_denoised_list.append(msi_img_denoised)\n",
    "\n",
    "# Display denoised images\n",
    "for i in range(len(msi_img_denoised_list))[:10]:\n",
    "    plt.imshow(msi_img_denoised_list[i], cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47725db6-c00f-4de0-b298-f819600b7711",
   "metadata": {},
   "source": [
    "### different spatial regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f7e02b1-8765-4b92-8bfb-dd0e2a57c168",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patch 1/1: 100%|████████████████████████████████████████████████████| 16/16 [02:47<00:00, 10.47s/it, consistency=35.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "iteration_num = 512\n",
    "epoch = 64\n",
    "n_fold = 1\n",
    "custom_params = {\n",
    "    'model_type': PixTransformNetBase,\n",
    "    'greyscale': True,\n",
    "    'channels': -1, \n",
    "    'bicubic_input': False,\n",
    "    'spatial_features_input': True,\n",
    "    'weights_regularizer': [0, 0.001, 0.001],  # spatial color head\n",
    "    'loss': 'l1',\n",
    "    'optim': 'adam',\n",
    "    'lr': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'iteration': iteration_num * epoch,\n",
    "    'logstep': 512,\n",
    "    'patch_size': guide_size,\n",
    "    'stride': 256\n",
    "}\n",
    "\n",
    "def PixTransform_with_different_spatial_regs(guide_img, source_img, base_params, spatial_regs, n_fold):\n",
    "    \"\"\"\n",
    "    Apply PixTransform with different spatial regularizer values and return individual predictions and averaged result.\n",
    "    \n",
    "    Parameters:\n",
    "    - guide_img (numpy array): The guiding image for the PixTransform model.\n",
    "    - source_img (numpy array): The source image to be transformed.\n",
    "    - base_params (dict): Base parameters for the PixTransform model.\n",
    "    - spatial_regs (list of float): Different spatial regularizer values to be tested.\n",
    "    \n",
    "    Returns:\n",
    "    - results (dict): A dictionary where the key is the spatial regularizer value, and the value is a list of predictions for each image.\n",
    "    - averaged_prediction (numpy array): The averaged prediction result from different spatial regularizers.\n",
    "    \"\"\"\n",
    "    predictions = []  # To store predictions for averaging\n",
    "    results = {str(spatial_reg): [] for spatial_reg in spatial_regs}\n",
    "    \n",
    "    for spatial_reg in spatial_regs:\n",
    "        params = base_params.copy()  # Copy base params to modify\n",
    "        params['weights_regularizer'][0] = spatial_reg  # Update the spatial regularizer\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Perform PixTransform with the current spatial regularizer\n",
    "        predictions_n_fold = []\n",
    "        for i in range(n_fold):\n",
    "            predicted_img_n_fold = PixTransform_diff_models(guide_img=guide_img, source_img=source_img, params=params)\n",
    "            predictions_n_fold.append(predicted_img_n_fold)\n",
    "        predicted_img = np.mean(predictions_n_fold, axis=0)\n",
    "        \n",
    "        # Append the predicted image to the respective spatial regularizer in the dictionary\n",
    "        results[str(spatial_reg)].append(predicted_img)\n",
    "        \n",
    "        # Store the predicted image for averaging\n",
    "        predictions.append(predicted_img)\n",
    "    \n",
    "    # Compute the average of the predictions across spatial regularizers\n",
    "    averaged_prediction = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return results, averaged_prediction\n",
    "\n",
    "# Example usage:\n",
    "denoise = False\n",
    "enhance = False\n",
    "spatial_regs = [0.001]  # Different spatial regularizer values to try\n",
    "\n",
    "'''guide_final = np.zeros((3, guide_size, guide_size))\n",
    "guide_final[0,:,:] = guide_resized[:,:,0]\n",
    "guide_final[1,:,:] = guide_resized[:,:,1]\n",
    "guide_final[2,:,:] = guide_resized[:,:,2]'''\n",
    "guide_final = guide_resized.copy()\n",
    "#guide_final = guide_resized_cropped.copy()\n",
    "\n",
    "# Initialize the dictionary to store individual predictions\n",
    "individual_predictions_dict = {str(spatial_reg): [] for spatial_reg in spatial_regs}\n",
    "predicted_target_img_list = []  # List to store the averaged predictions\n",
    "\n",
    "for i in range(len(msi_img_final_cropped_list)):  # Iterate through the msi images\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if denoise:\n",
    "        source_img = msi_img_denoised_list[i]\n",
    "    if enhance:\n",
    "        source_img = msi_img_contrast_enhanced_list[i]\n",
    "    else:\n",
    "        source_img = msi_img_resized_list[i]\n",
    "    \n",
    "    # Get the dictionary of predictions and the averaged prediction for each image\n",
    "    predictions_dict, averaged_prediction = PixTransform_with_different_spatial_regs(\n",
    "        guide_final, source_img, custom_params, spatial_regs, n_fold\n",
    "    )\n",
    "    \n",
    "    # Store the individual predictions for each spatial reg\n",
    "    for spatial_reg in spatial_regs:\n",
    "        individual_predictions_dict[str(spatial_reg)].append(predictions_dict[str(spatial_reg)][0])\n",
    "    \n",
    "    # Store the averaged prediction\n",
    "    predicted_target_img_list.append(averaged_prediction)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08e792-7647-4b72-833e-47e507604aed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Local contrast adjustment functions\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "# Set up directories\n",
    "unique_id = 35\n",
    "base_dir = f'Y:\\\\coskun-lab\\\\Efe and Nishkala\\\\gsrmsi\\\\GUIDEDSR\\\\09_30_2024\\\\integration_mass_cytometry_data\\\\{unique_id}'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "def match_local_statistics_with_details(src, ref, patch_size, stride):\n",
    "    src_padded = np.pad(src, patch_size // 2, mode='reflect')\n",
    "    ref_padded = np.pad(ref, patch_size // 2, mode='reflect')\n",
    "    \n",
    "    src_matched = np.zeros_like(src)\n",
    "    \n",
    "    for i in range(0, src.shape[0], stride):\n",
    "        for j in range(0, src.shape[1], stride):\n",
    "            src_patch = src_padded[i:i + patch_size, j:j + patch_size]\n",
    "            ref_patch = ref_padded[i:i + patch_size, j:j + patch_size]\n",
    "            \n",
    "            src_mean, src_std = cv2.meanStdDev(src_patch)\n",
    "            ref_mean, ref_std = cv2.meanStdDev(ref_patch)\n",
    "            \n",
    "            src_patch_normalized = (src_patch - src_mean) / (src_std + 1e-8)\n",
    "            src_patch_matched = ref_mean + src_patch_normalized * ref_std\n",
    "            \n",
    "            src_matched[i:i + stride, j:j + stride] = src_patch_matched[patch_size // 2, patch_size // 2]\n",
    "    \n",
    "    return src_matched\n",
    "\n",
    "def enhance_local_contrast_with_details(src, ref, patch_size=15, stride=1):\n",
    "    # Step 1: Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
    "    src_clahe = clahe.apply((src * 255).astype(np.uint8)) / 255.0\n",
    "    \n",
    "    # Step 2: Match local statistics\n",
    "    src_matched = match_local_statistics_with_details(src_clahe, ref, patch_size, stride)\n",
    "    \n",
    "    # Step 3: Compute detail layer\n",
    "    src_blurred = cv2.GaussianBlur(src, (patch_size, patch_size), 0)\n",
    "    detail_layer = src - src_blurred\n",
    "    \n",
    "    # Step 4: Add detail layer back to the matched image\n",
    "    result = src_matched + detail_layer\n",
    "    result = np.clip(result, 0, 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Initialize the dictionary to store combined results and individual predictions\n",
    "combined_results_adjusted_lst = []\n",
    "individual_predictions_adjusted_dict = {str(spatial_reg): [] for spatial_reg in spatial_regs}  # Store adjusted individual predictions\n",
    "\n",
    "for i in range(len(msi_img_resized_list)):  # Iterate through MSI images\n",
    "    msi_upsampled = cv2.resize(msi_img_resized_list[i], (guide_size, guide_size), interpolation=cv2.INTER_NEAREST)\n",
    "    msi_upsampled = msi_upsampled.astype(np.float32)\n",
    "    msi_upsampled /= 255.0\n",
    "    #msi_upsampled = msi_upsampled.astype(np.float32) / np.iinfo(np.uint16).max\n",
    "\n",
    "    # Combined predictions across spatial regularizers\n",
    "    combined = np.zeros((guide_resized.shape[0], guide_resized.shape[1]))\n",
    "    total_regs = len(spatial_regs)  # Total number of spatial regularizers\n",
    "\n",
    "    for spatial_reg in spatial_regs:\n",
    "        individual_pred = individual_predictions_dict[str(spatial_reg)][i].copy()\n",
    "\n",
    "        # **Save individual spatial reg combinations**\n",
    "        individual_pred_adjusted = cv2.normalize(individual_pred, None, 0, 1, cv2.NORM_MINMAX).astype('float32')\n",
    "\n",
    "        # Apply local contrast enhancement with details\n",
    "        individual_pred_adjusted = enhance_local_contrast_with_details(individual_pred_adjusted, msi_upsampled)\n",
    "\n",
    "        # Store the adjusted individual prediction\n",
    "        individual_predictions_adjusted_dict[str(spatial_reg)].append(individual_pred_adjusted)\n",
    "\n",
    "        # Save the individual prediction with spatial reg details in the filename\n",
    "        plt.figure()\n",
    "        plt.imshow(individual_pred_adjusted, cmap=\"viridis\")\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'{base_dir}\\\\super_res_msi_{i+1}_{unique_id}_spatial_reg_{str(spatial_reg)}.jpg', dpi=1200, bbox_inches='tight', pad_inches=0)\n",
    "        np.save(f'{base_dir}\\\\super_res_msi_{i+1}_{unique_id}_spatial_reg_{str(spatial_reg)}.npy', individual_pred_adjusted)\n",
    "\n",
    "        # Add individual prediction to the combined result\n",
    "        combined += individual_pred\n",
    "\n",
    "    # Normalize the combined output by the total number of spatial regularizers\n",
    "    combined /= total_regs\n",
    "\n",
    "    # Apply local contrast enhancement to the combined result\n",
    "    combined = cv2.normalize(combined, None, 0, 1, cv2.NORM_MINMAX).astype('float32')\n",
    "    combined_adjusted = enhance_local_contrast_with_details(combined, msi_upsampled)\n",
    "    combined_adjusted = cv2.normalize(combined_adjusted, None, 0, 1, cv2.NORM_MINMAX).astype('float32')\n",
    "    combined_results_adjusted_lst.append(combined_adjusted)\n",
    "\n",
    "    # Save the combined prediction\n",
    "    plt.figure()\n",
    "    plt.imshow(combined_adjusted, cmap=\"viridis\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{base_dir}\\\\super_res_msi_{i+1}_{unique_id}_combined.jpg', dpi=1200, bbox_inches='tight', pad_inches=0)\n",
    "    np.save(f'{base_dir}\\\\super_res_msi_{i+1}_{unique_id}_combined.npy', combined_adjusted)\n",
    "\n",
    "# Clean up memory after processing\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a81d31b6-dc5f-4052-8be1-b0298738cde9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_id = 35\n",
    "base_dir = f'Y:\\\\coskun-lab\\\\Efe and Nishkala\\\\gsrmsi\\\\GUIDEDSR\\\\09_30_2024\\\\integration_mass_cytometry_data\\\\{unique_id}'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "params = {'iteration_num*epoch': f'{iteration_num}*{epoch}', 'guide_size': guide_size, 'source_size': source_size}\n",
    "params_filename = f\"{base_dir}\\\\params_{unique_id}.txt\"\n",
    "with open(params_filename, 'w') as params_file:\n",
    "    params_file.write(f\"unique_id = {unique_id}\\n\")\n",
    "    for key, value in params.items():\n",
    "        params_file.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "plt.figure() \n",
    "plt.imshow(guide_resized, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{base_dir}\\\\guide_{unique_id}.jpg', dpi=1200, bbox_inches='tight', pad_inches=0)\n",
    "plt.close() \n",
    "\n",
    "np.save(f'{base_dir}\\\\guide_{unique_id}.npy', guide_resized)\n",
    "\n",
    "for i in range(len(msi_img_resized_list)):\n",
    "    plt.figure()\n",
    "    msi_upsampled = cv2.resize(msi_img_resized_list[i], (guide_size, guide_size), interpolation=cv2.INTER_NEAREST)\n",
    "    msi_upsampled = msi_upsampled.astype(np.float32)\n",
    "    msi_upsampled /= 255.0\n",
    "    \n",
    "    plt.imshow(msi_upsampled)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{base_dir}\\\\low_res_msi_{i+1}_{unique_id}.jpg', dpi=1200, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    np.save(f'{base_dir}\\\\low_res_msi_{i+1}_{unique_id}.npy', cv2.resize(msi_img_resized_list[i], (guide_size, guide_size), interpolation=cv2.INTER_NEAREST))\n",
    "\n",
    "for i in range(len(msi_img_resized_list)):\n",
    "    plt.figure()\n",
    "    \n",
    "    raw_output = cv2.normalize(predicted_target_img_list[i], None, 0, 1, cv2.NORM_MINMAX).astype('float32')\n",
    "    \n",
    "    plt.imshow(raw_output)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{base_dir}\\\\raw_output_{i+1}_{unique_id}.jpg', dpi=1200, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    np.save(f'{base_dir}\\\\raw_output_{i+1}_{unique_id}.npy', raw_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu2",
   "language": "python",
   "name": "torch_gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
